{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:04.150932Z",
     "start_time": "2025-08-21T09:02:04.148650Z"
    }
   },
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "from IPython.display import Markdown, display"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:04.165987Z",
     "start_time": "2025-08-21T09:02:04.163059Z"
    }
   },
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:04.178196Z",
     "start_time": "2025-08-21T09:02:04.175932Z"
    }
   },
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "openai_api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins with {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n",
    "if openai_endpoint:\n",
    "    print(f\"OpenAI API Endpoint exists: {openai_endpoint}\")\n",
    "else:\n",
    "    print(\"OpenAI API Endpoint not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n",
    "if openai_api_version:\n",
    "    print(f\"OpenAI API Version exists: {openai_api_version}\")\n",
    "else:\n",
    "    print(\"OpenAI API Version not set - please head to the troubleshooting guide in the setup folder\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins with dial-7q1\n",
      "OpenAI API Endpoint exists: https://ai-proxy.lab.epam.com\n",
      "OpenAI API Version exists: 2024-12-01-preview\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:04.186457Z",
     "start_time": "2025-08-21T09:02:04.185047Z"
    }
   },
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:04.195249Z",
     "start_time": "2025-08-21T09:02:04.193475Z"
    }
   },
   "source": [
    "messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:05.914120Z",
     "start_time": "2025-08-21T09:02:04.202572Z"
    }
   },
   "source": [
    "dial = AzureOpenAI()\n",
    "response = dial.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts?\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:05.929644Z",
     "start_time": "2025-08-21T09:02:05.928043Z"
    }
   },
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:14.421395Z",
     "start_time": "2025-08-21T09:02:05.936037Z"
    }
   },
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "response = dial.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, involves a multi-faceted approach. Here’s how I would approach this task:\n\n### 1. **Stakeholder Engagement**\n   - **Inclusivity**: Engage a diverse group of stakeholders, including technologists, ethicists, sociologists, policymakers, business leaders, and community representatives from different cultural backgrounds.\n   - **Public Consultation**: Conduct workshops, surveys, and focus groups to capture a wide range of views and concerns. This will help ensure the framework reflects various cultural perspectives and socio-economic contexts.\n\n### 2. **Core Principles Development**\n   - **Transparency**: Ensure that AI systems are built on transparent processes that allow stakeholders to understand how decisions are made.\n   - **Accountability**: Define clear accountability mechanisms for the development and deployment of AI technologies, including who is responsible when things go wrong.\n   - **Fairness and Non-discrimination**: Ensure that AI systems do not perpetuate biases or inequities. This includes ongoing audits for fairness and active measures to avoid discrimination across different socio-economic groups.\n   - **Safety and Security**: Incorporate risk assessment protocols that prioritize the safety and security of users and sensitive data.\n\n### 3. **Cultural Sensitivity**\n   - **Culturally Adaptive Standards**: Develop guidelines that allow for flexibility in implementation based on cultural norms and values, acknowledging that ethical considerations can differ across societies.\n   - **Global Collaboration**: Encourage international partnerships to share best practices and learn from various cultural frameworks surrounding AI ethics.\n\n### 4. **Regulatory and Policy Framework**\n   - **Collaborative Standards**: Work with regulatory bodies to create adaptable policy frameworks that promote responsible AI innovation while ensuring safety protocols are met.\n   - **Sandbox Environments**: Establish “regulatory sandboxes” where innovative AI applications can be tested in controlled environments, allowing for iterative learning and adjustment without risking public harm.\n\n### 5. **Impact Assessment and Monitoring**\n   - **Socio-economic Impact Assessments**: Require assessments to evaluate the potential socio-economic impacts of AI technologies, considering both positive and negative outcomes.\n   - **Continuous Monitoring**: Implement ongoing monitoring mechanisms to assess the real-world impacts of AI systems post-deployment and adapt the framework as necessary.\n\n### 6. **Education and Awareness**\n   - **Public Awareness Campaigns**: Develop initiatives to educate the public about AI technologies and their potential impacts, fostering an informed citizenry that can engage in ethical discussions.\n   - **Training for Stakeholders**: Provide training programs for developers, companies, and public officials on ethical AI principles, cultural sensitivity, and the socio-economic implications of AI technologies.\n\n### 7. **Research and Development Support**\n   - **Innovation Incentives**: Promote R&D that seeks to strike the balance between safety and innovation, potentially through grants or funding for projects that prioritize ethical considerations.\n   - **Cross-disciplinary Collaboration**: Encourage collaboration among computer scientists, social scientists, and humanities scholars to explore the societal impact of AI and inform ethical standards.\n\n### Conclusion\nThe creation of an ethical framework for AI requires a comprehensive and adaptable approach that values diverse perspectives, addresses socio-economic realities, and balances the urgency for innovation with the necessity of safety. Continuous dialogue, stakeholder engagement, and an emphasis on education will be key to fostering responsible AI that benefits society as a whole."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:20.046576Z",
     "start_time": "2025-08-21T09:02:14.444380Z"
    }
   },
   "source": [
    "model_name = \"claude-3-7-sonnet@20250219\"\n",
    "\n",
    "response = dial.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Designing an Ethical Framework for AI Systems\n\nI'd approach this multifaceted challenge through these interconnected elements:\n\n## Core Principles\n- Establish universal baseline principles (safety, fairness, transparency) while allowing flexibility for cultural contexts\n- Implement tiered ethics requirements proportional to an AI system's potential impact\n- Ensure the framework evolves alongside technological advancement\n\n## Inclusive Development Process\n- Form a diverse global working group representing varied disciplines, cultures, and socioeconomic perspectives\n- Include historically marginalized voices and non-Western ethical traditions\n- Create feedback mechanisms to capture real-world impacts across different communities\n\n## Practical Implementation\n- Develop concrete guidelines for translating abstract principles into technical specifications\n- Require impact assessments examining potential harm to vulnerable populations\n- Establish governance mechanisms with meaningful oversight and accountability\n\n## Balancing Innovation and Safety\n- Create regulatory sandboxes where higher-risk innovations can be tested in controlled environments\n- Design graduated regulatory responses based on risk assessment\n- Focus restrictions on applications rather than foundational research\n\nWhat aspect of this framework would you like me to elaborate on further?"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:32.331476Z",
     "start_time": "2025-08-21T09:02:20.061847Z"
    }
   },
   "source": [
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = dial.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts is a complex and multi-faceted challenge. Here's a comprehensive approach:\n\n**I. Core Principles and Values:**\n\n*   **Human-centricity:** Prioritize human well-being, autonomy, and dignity above all else. AI should serve humanity, not the other way around.\n*   **Beneficence and Non-maleficence:**  AI systems should strive to maximize positive impact and minimize harm.  This includes physical, psychological, economic, and social harms.\n*   **Fairness and Justice:** Ensure equitable access to AI benefits and equitable distribution of AI-related risks, avoiding discrimination and bias.\n*   **Transparency and Explainability:** AI systems should be understandable and their decision-making processes should be transparent where possible, allowing for accountability and redress.\n*   **Privacy and Data Security:**  Protect individuals' privacy and ensure the secure handling of data used by AI systems. Implement strong data governance principles.\n*   **Accountability:** Establish clear lines of responsibility for the development, deployment, and consequences of AI systems.\n*   **Sustainability:** Consider the environmental impact of AI development and deployment, promoting sustainable practices.\n*   **Respect for Human Rights:** Ensure AI systems are designed and used in a manner that respects all human rights, including freedom of speech, expression, and assembly.\n*   **Cultural Sensitivity:** Acknowledge and address the diverse cultural values, beliefs, and norms that may be impacted by AI systems.\n\n**II. Stakeholder Engagement and Consultation:**\n\n*   **Involve diverse voices:**  Engage a broad range of stakeholders, including:\n    *   AI developers and researchers\n    *   Ethicists and philosophers\n    *   Legal experts\n    *   Policymakers and regulators\n    *   Civil society organizations\n    *   Affected communities (including marginalized and vulnerable groups)\n    *   Businesses and industry representatives\n*   **Global perspective:**  Solicit input from individuals and organizations from different countries and cultures to ensure inclusivity and avoid Western-centric biases.\n*   **Consultation methods:**  Utilize a variety of methods for gathering input, such as:\n    *   Public forums and workshops\n    *   Surveys and questionnaires\n    *   Focus groups\n    *   Online platforms for feedback\n    *   Expert panels and advisory boards\n*   **Iterative process:**  Continuously refine the ethical framework based on stakeholder feedback and evolving AI technologies.\n\n**III. Framework Components:**\n\n1.  **Ethical Guidelines for AI Development:**\n\n    *   **Bias detection and mitigation:** Implement techniques to identify and address biases in data and algorithms.  This includes using diverse datasets and fairness-aware algorithms.\n    *   **Explainability methods:**  Employ methods to make AI decision-making more understandable, such as SHAP values, LIME, and counterfactual explanations.\n    *   **Privacy-preserving techniques:**  Utilize techniques like differential privacy, federated learning, and homomorphic encryption to protect user data.\n    *   **Security protocols:**  Implement robust security measures to prevent malicious use of AI systems and protect against data breaches.\n    *   **Testing and validation:**  Thoroughly test and validate AI systems to ensure they are safe, reliable, and perform as expected. This includes adversarial testing and stress testing.\n    *   **Monitoring and auditing:** Continuously monitor AI systems for unintended consequences and audit their performance for fairness and accuracy.\n    *   **Documentation:**  Maintain comprehensive documentation of the AI system's design, development, and deployment, including ethical considerations and risk assessments.\n    *   **Human oversight:**  Establish mechanisms for human oversight and intervention in AI decision-making processes, especially in high-stakes applications.\n\n2.  **Ethical Framework for AI Deployment:**\n\n    *   **Impact assessment:** Conduct thorough impact assessments before deploying AI systems, considering potential social, economic, and environmental consequences.\n    *   **Transparency with users:**  Clearly communicate to users how AI systems are being used and how they might affect them.\n    *   **User control:**  Empower users with control over their data and the ability to opt-out of AI-driven services.\n    *   **Redress mechanisms:**  Establish mechanisms for individuals to seek redress if they are harmed by an AI system. This could include dispute resolution processes and legal remedies.\n    *   **Skill development and job transition programs:** Implement programs to support workers who may be displaced by AI-driven automation.\n    *   **Regulation and governance:**  Develop appropriate regulatory frameworks to govern the development and deployment of AI, balancing innovation with safety and ethical considerations.  These regulations may need to vary across sectors.\n    *   **International cooperation:**  Promote international collaboration and harmonization of ethical standards for AI.\n\n3.  **Addressing Socio-Economic Impacts:**\n\n    *   **Economic inequality:** Implement policies to address the potential for AI to exacerbate economic inequality, such as progressive taxation, universal basic income, and investment in education and training.\n    *   **Job displacement:**  Invest in retraining programs and create new job opportunities in emerging fields. Explore alternative work arrangements, such as shorter workweeks and job sharing.\n    *   **Access to technology:**  Ensure equitable access to AI-driven technologies and services, especially for underserved communities.\n    *   **Digital literacy:**  Promote digital literacy skills to empower individuals to use AI-powered tools and services effectively.\n    *   **Fair competition:**  Foster fair competition in the AI market to prevent monopolies and promote innovation.\n\n4.  **Addressing Cultural Considerations:**\n\n    *   **Cultural sensitivity training:**  Provide cultural sensitivity training to AI developers and policymakers.\n    *   **Localization:**  Adapt AI systems to local languages, cultural norms, and values.\n    *   **Participatory design:**  Involve local communities in the design and development of AI systems to ensure they are culturally appropriate.\n    *   **Respect for cultural heritage:**  Protect cultural heritage from potential harm caused by AI systems, such as the spread of misinformation or the appropriation of cultural artifacts.\n    *   **Recognize diverse perspectives:**  Acknowledge that ethical considerations may vary across cultures and avoid imposing a single, universal ethical framework.\n    *   **Promote cross-cultural dialogue:**  Facilitate dialogue and collaboration between different cultures to foster a shared understanding of ethical AI.\n\n**IV. Implementation and Enforcement:**\n\n*   **Self-regulation:** Encourage industry self-regulation through the development of ethical codes of conduct and best practices.\n*   **Certification and auditing:**  Establish certification and auditing programs to ensure that AI systems meet ethical standards.\n*   **Regulatory oversight:**  Implement regulatory oversight and enforcement mechanisms to address egregious violations of ethical principles.\n*   **Liability frameworks:**  Clarify liability frameworks for harms caused by AI systems.\n*   **Education and awareness:**  Promote education and awareness of ethical issues in AI among the general public.\n\n**V. Ongoing Review and Adaptation:**\n\n*   **Regular evaluation:**  Regularly evaluate the effectiveness of the ethical framework and make adjustments as needed to reflect technological advancements and evolving societal values.\n*   **Continuous learning:**  Stay abreast of the latest research and best practices in ethical AI.\n*   **Adaptable framework:**  Design the framework to be flexible and adaptable to new challenges and opportunities presented by AI.\n\n**Key Considerations for Success:**\n\n*   **Strong leadership:**  Effective leadership is crucial to drive the development and implementation of the ethical framework.\n*   **Collaboration and coordination:**  Collaboration and coordination among stakeholders are essential for building consensus and ensuring that the framework is effectively implemented.\n*   **Resources:**  Adequate resources are needed to support research, development, and implementation of ethical AI practices.\n*   **Political will:**  Political will is needed to enact and enforce regulations and policies that promote ethical AI.\n*   **Public trust:** Building and maintaining public trust in AI is essential for its widespread adoption and acceptance.\n\nBy following this comprehensive approach, we can create an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, ultimately ensuring that AI serves humanity in a responsible and beneficial way. It's a continuous journey, requiring vigilance, adaptation, and a commitment to ethical principles.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:34.538045Z",
     "start_time": "2025-08-21T09:02:32.348589Z"
    }
   },
   "source": [
    "!ollama pull llama3.2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠙ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠙ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠹ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠼ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠼ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠴ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠦ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠇ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠇ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠏ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠋ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠙ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠹ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠸ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠴ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠦ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠦ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠇ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠇ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠋ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\r\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001B[K\r\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001B[K\r\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001B[K\r\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001B[K\r\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001B[K\r\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001B[K\r\n",
      "verifying sha256 digest \u001B[K\r\n",
      "writing manifest \u001B[K\r\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\r\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.108282Z",
     "start_time": "2025-08-21T09:02:34.551503Z"
    }
   },
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Designing an ethical framework for AI systems requires a multidisciplinary approach that considers various factors, including technical, social, and economic aspects. Here's a comprehensive framework to balance innovation with safety, diversity, and socio-economic considerations:\n\n1. **Establish a Clear Purpose and Scope**:\n Define the purpose of the AI system, its intended use cases, and the stakeholders involved. This will help identify potential risks and benefits, as well as the necessary safeguards.\n2. **Conduct Thorough Risk Assessments**:\n Perform comprehensive risk assessments to understand potential threats and opportunities. Identify potential risks, such as data bias, bias in decision-making, or unintended consequences on society.\n3. **Develop a Human-Centered Approach**:\n Prioritize human needs, dignity, and well-being in AI system design. Ensure that the framework takes into account diverse cultural perspectives, values, and contexts to prevent cultural homogenization or exploitation.\n4. **Foster Collaboration and Stakeholder Engagement**:\n Engage with diverse stakeholders, including experts from various fields (e.g., ethics, law, sociology), industry representatives, policymakers, and community representatives to ensure that the AI system is aligned with societal values and needs.\n5. **Incorporate Transparency and Explainability**:\n Develop techniques to explain AI decision-making processes and provide transparent outputs. This will enable users to understand how AI systems make decisions and promote accountability.\n6. **Emphasize Fairness, Accountability, and Resilience**:\n Incorporate principles of fairness, accountability, and resilience into the framework. Ensure that AI systems are fair, unbiased, and resilient in the face of failures or cyber-attacks.\n7. **Consider Socio-Economic Impacts**:\n Assess potential socio-economic impacts, including job displacement, inequality, or amplification of existing biases. Develop mitigation strategies to minimize these effects.\n8. **Establish Robust Auditing and Monitoring Processes**:\n Regularly audit and monitor AI systems for compliance with the framework's principles and ensure that necessary safeguards are in place.\n9. **Continuously Evaluate and Update the Framework**:\n Regularly review and update the framework to address emerging challenges, technical advancements, or new societal values.\n10. **Promote Public Engagement and Education**:\n Educate stakeholders and the public about AI-related issues and promote informed discussions on AI development and deployment.\n\nSome additional considerations:\n\n*   **Accountability Mechanisms**: Establish accountability mechanisms for AI system developers, users, and regulators to ensure that the framework is enforced and respected.\n*   **Global Harmonization**: Foster international cooperation to develop harmonized standards for AI ethics and governance, ensuring consistency across borders.\n*   **Research and Development**: Support ongoing research and development to improve understanding of AI systems' potential risks and benefits.\n\nBy incorporating these elements into an ethical framework for AI systems, we can ensure that innovation is balanced with safety, diversity, and socio-economic considerations."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.138844Z",
     "start_time": "2025-08-21T09:02:41.136651Z"
    }
   },
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini-2024-07-18', 'claude-3-7-sonnet@20250219', 'gemini-2.0-flash', 'llama3.2']\n",
      "['Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, involves a multi-faceted approach. Here’s how I would approach this task:\\n\\n### 1. **Stakeholder Engagement**\\n   - **Inclusivity**: Engage a diverse group of stakeholders, including technologists, ethicists, sociologists, policymakers, business leaders, and community representatives from different cultural backgrounds.\\n   - **Public Consultation**: Conduct workshops, surveys, and focus groups to capture a wide range of views and concerns. This will help ensure the framework reflects various cultural perspectives and socio-economic contexts.\\n\\n### 2. **Core Principles Development**\\n   - **Transparency**: Ensure that AI systems are built on transparent processes that allow stakeholders to understand how decisions are made.\\n   - **Accountability**: Define clear accountability mechanisms for the development and deployment of AI technologies, including who is responsible when things go wrong.\\n   - **Fairness and Non-discrimination**: Ensure that AI systems do not perpetuate biases or inequities. This includes ongoing audits for fairness and active measures to avoid discrimination across different socio-economic groups.\\n   - **Safety and Security**: Incorporate risk assessment protocols that prioritize the safety and security of users and sensitive data.\\n\\n### 3. **Cultural Sensitivity**\\n   - **Culturally Adaptive Standards**: Develop guidelines that allow for flexibility in implementation based on cultural norms and values, acknowledging that ethical considerations can differ across societies.\\n   - **Global Collaboration**: Encourage international partnerships to share best practices and learn from various cultural frameworks surrounding AI ethics.\\n\\n### 4. **Regulatory and Policy Framework**\\n   - **Collaborative Standards**: Work with regulatory bodies to create adaptable policy frameworks that promote responsible AI innovation while ensuring safety protocols are met.\\n   - **Sandbox Environments**: Establish “regulatory sandboxes” where innovative AI applications can be tested in controlled environments, allowing for iterative learning and adjustment without risking public harm.\\n\\n### 5. **Impact Assessment and Monitoring**\\n   - **Socio-economic Impact Assessments**: Require assessments to evaluate the potential socio-economic impacts of AI technologies, considering both positive and negative outcomes.\\n   - **Continuous Monitoring**: Implement ongoing monitoring mechanisms to assess the real-world impacts of AI systems post-deployment and adapt the framework as necessary.\\n\\n### 6. **Education and Awareness**\\n   - **Public Awareness Campaigns**: Develop initiatives to educate the public about AI technologies and their potential impacts, fostering an informed citizenry that can engage in ethical discussions.\\n   - **Training for Stakeholders**: Provide training programs for developers, companies, and public officials on ethical AI principles, cultural sensitivity, and the socio-economic implications of AI technologies.\\n\\n### 7. **Research and Development Support**\\n   - **Innovation Incentives**: Promote R&D that seeks to strike the balance between safety and innovation, potentially through grants or funding for projects that prioritize ethical considerations.\\n   - **Cross-disciplinary Collaboration**: Encourage collaboration among computer scientists, social scientists, and humanities scholars to explore the societal impact of AI and inform ethical standards.\\n\\n### Conclusion\\nThe creation of an ethical framework for AI requires a comprehensive and adaptable approach that values diverse perspectives, addresses socio-economic realities, and balances the urgency for innovation with the necessity of safety. Continuous dialogue, stakeholder engagement, and an emphasis on education will be key to fostering responsible AI that benefits society as a whole.', \"# Designing an Ethical Framework for AI Systems\\n\\nI'd approach this multifaceted challenge through these interconnected elements:\\n\\n## Core Principles\\n- Establish universal baseline principles (safety, fairness, transparency) while allowing flexibility for cultural contexts\\n- Implement tiered ethics requirements proportional to an AI system's potential impact\\n- Ensure the framework evolves alongside technological advancement\\n\\n## Inclusive Development Process\\n- Form a diverse global working group representing varied disciplines, cultures, and socioeconomic perspectives\\n- Include historically marginalized voices and non-Western ethical traditions\\n- Create feedback mechanisms to capture real-world impacts across different communities\\n\\n## Practical Implementation\\n- Develop concrete guidelines for translating abstract principles into technical specifications\\n- Require impact assessments examining potential harm to vulnerable populations\\n- Establish governance mechanisms with meaningful oversight and accountability\\n\\n## Balancing Innovation and Safety\\n- Create regulatory sandboxes where higher-risk innovations can be tested in controlled environments\\n- Design graduated regulatory responses based on risk assessment\\n- Focus restrictions on applications rather than foundational research\\n\\nWhat aspect of this framework would you like me to elaborate on further?\", \"Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts is a complex and multi-faceted challenge. Here's a comprehensive approach:\\n\\n**I. Core Principles and Values:**\\n\\n*   **Human-centricity:** Prioritize human well-being, autonomy, and dignity above all else. AI should serve humanity, not the other way around.\\n*   **Beneficence and Non-maleficence:**  AI systems should strive to maximize positive impact and minimize harm.  This includes physical, psychological, economic, and social harms.\\n*   **Fairness and Justice:** Ensure equitable access to AI benefits and equitable distribution of AI-related risks, avoiding discrimination and bias.\\n*   **Transparency and Explainability:** AI systems should be understandable and their decision-making processes should be transparent where possible, allowing for accountability and redress.\\n*   **Privacy and Data Security:**  Protect individuals' privacy and ensure the secure handling of data used by AI systems. Implement strong data governance principles.\\n*   **Accountability:** Establish clear lines of responsibility for the development, deployment, and consequences of AI systems.\\n*   **Sustainability:** Consider the environmental impact of AI development and deployment, promoting sustainable practices.\\n*   **Respect for Human Rights:** Ensure AI systems are designed and used in a manner that respects all human rights, including freedom of speech, expression, and assembly.\\n*   **Cultural Sensitivity:** Acknowledge and address the diverse cultural values, beliefs, and norms that may be impacted by AI systems.\\n\\n**II. Stakeholder Engagement and Consultation:**\\n\\n*   **Involve diverse voices:**  Engage a broad range of stakeholders, including:\\n    *   AI developers and researchers\\n    *   Ethicists and philosophers\\n    *   Legal experts\\n    *   Policymakers and regulators\\n    *   Civil society organizations\\n    *   Affected communities (including marginalized and vulnerable groups)\\n    *   Businesses and industry representatives\\n*   **Global perspective:**  Solicit input from individuals and organizations from different countries and cultures to ensure inclusivity and avoid Western-centric biases.\\n*   **Consultation methods:**  Utilize a variety of methods for gathering input, such as:\\n    *   Public forums and workshops\\n    *   Surveys and questionnaires\\n    *   Focus groups\\n    *   Online platforms for feedback\\n    *   Expert panels and advisory boards\\n*   **Iterative process:**  Continuously refine the ethical framework based on stakeholder feedback and evolving AI technologies.\\n\\n**III. Framework Components:**\\n\\n1.  **Ethical Guidelines for AI Development:**\\n\\n    *   **Bias detection and mitigation:** Implement techniques to identify and address biases in data and algorithms.  This includes using diverse datasets and fairness-aware algorithms.\\n    *   **Explainability methods:**  Employ methods to make AI decision-making more understandable, such as SHAP values, LIME, and counterfactual explanations.\\n    *   **Privacy-preserving techniques:**  Utilize techniques like differential privacy, federated learning, and homomorphic encryption to protect user data.\\n    *   **Security protocols:**  Implement robust security measures to prevent malicious use of AI systems and protect against data breaches.\\n    *   **Testing and validation:**  Thoroughly test and validate AI systems to ensure they are safe, reliable, and perform as expected. This includes adversarial testing and stress testing.\\n    *   **Monitoring and auditing:** Continuously monitor AI systems for unintended consequences and audit their performance for fairness and accuracy.\\n    *   **Documentation:**  Maintain comprehensive documentation of the AI system's design, development, and deployment, including ethical considerations and risk assessments.\\n    *   **Human oversight:**  Establish mechanisms for human oversight and intervention in AI decision-making processes, especially in high-stakes applications.\\n\\n2.  **Ethical Framework for AI Deployment:**\\n\\n    *   **Impact assessment:** Conduct thorough impact assessments before deploying AI systems, considering potential social, economic, and environmental consequences.\\n    *   **Transparency with users:**  Clearly communicate to users how AI systems are being used and how they might affect them.\\n    *   **User control:**  Empower users with control over their data and the ability to opt-out of AI-driven services.\\n    *   **Redress mechanisms:**  Establish mechanisms for individuals to seek redress if they are harmed by an AI system. This could include dispute resolution processes and legal remedies.\\n    *   **Skill development and job transition programs:** Implement programs to support workers who may be displaced by AI-driven automation.\\n    *   **Regulation and governance:**  Develop appropriate regulatory frameworks to govern the development and deployment of AI, balancing innovation with safety and ethical considerations.  These regulations may need to vary across sectors.\\n    *   **International cooperation:**  Promote international collaboration and harmonization of ethical standards for AI.\\n\\n3.  **Addressing Socio-Economic Impacts:**\\n\\n    *   **Economic inequality:** Implement policies to address the potential for AI to exacerbate economic inequality, such as progressive taxation, universal basic income, and investment in education and training.\\n    *   **Job displacement:**  Invest in retraining programs and create new job opportunities in emerging fields. Explore alternative work arrangements, such as shorter workweeks and job sharing.\\n    *   **Access to technology:**  Ensure equitable access to AI-driven technologies and services, especially for underserved communities.\\n    *   **Digital literacy:**  Promote digital literacy skills to empower individuals to use AI-powered tools and services effectively.\\n    *   **Fair competition:**  Foster fair competition in the AI market to prevent monopolies and promote innovation.\\n\\n4.  **Addressing Cultural Considerations:**\\n\\n    *   **Cultural sensitivity training:**  Provide cultural sensitivity training to AI developers and policymakers.\\n    *   **Localization:**  Adapt AI systems to local languages, cultural norms, and values.\\n    *   **Participatory design:**  Involve local communities in the design and development of AI systems to ensure they are culturally appropriate.\\n    *   **Respect for cultural heritage:**  Protect cultural heritage from potential harm caused by AI systems, such as the spread of misinformation or the appropriation of cultural artifacts.\\n    *   **Recognize diverse perspectives:**  Acknowledge that ethical considerations may vary across cultures and avoid imposing a single, universal ethical framework.\\n    *   **Promote cross-cultural dialogue:**  Facilitate dialogue and collaboration between different cultures to foster a shared understanding of ethical AI.\\n\\n**IV. Implementation and Enforcement:**\\n\\n*   **Self-regulation:** Encourage industry self-regulation through the development of ethical codes of conduct and best practices.\\n*   **Certification and auditing:**  Establish certification and auditing programs to ensure that AI systems meet ethical standards.\\n*   **Regulatory oversight:**  Implement regulatory oversight and enforcement mechanisms to address egregious violations of ethical principles.\\n*   **Liability frameworks:**  Clarify liability frameworks for harms caused by AI systems.\\n*   **Education and awareness:**  Promote education and awareness of ethical issues in AI among the general public.\\n\\n**V. Ongoing Review and Adaptation:**\\n\\n*   **Regular evaluation:**  Regularly evaluate the effectiveness of the ethical framework and make adjustments as needed to reflect technological advancements and evolving societal values.\\n*   **Continuous learning:**  Stay abreast of the latest research and best practices in ethical AI.\\n*   **Adaptable framework:**  Design the framework to be flexible and adaptable to new challenges and opportunities presented by AI.\\n\\n**Key Considerations for Success:**\\n\\n*   **Strong leadership:**  Effective leadership is crucial to drive the development and implementation of the ethical framework.\\n*   **Collaboration and coordination:**  Collaboration and coordination among stakeholders are essential for building consensus and ensuring that the framework is effectively implemented.\\n*   **Resources:**  Adequate resources are needed to support research, development, and implementation of ethical AI practices.\\n*   **Political will:**  Political will is needed to enact and enforce regulations and policies that promote ethical AI.\\n*   **Public trust:** Building and maintaining public trust in AI is essential for its widespread adoption and acceptance.\\n\\nBy following this comprehensive approach, we can create an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, ultimately ensuring that AI serves humanity in a responsible and beneficial way. It's a continuous journey, requiring vigilance, adaptation, and a commitment to ethical principles.\\n\", \"Designing an ethical framework for AI systems requires a multidisciplinary approach that considers various factors, including technical, social, and economic aspects. Here's a comprehensive framework to balance innovation with safety, diversity, and socio-economic considerations:\\n\\n1. **Establish a Clear Purpose and Scope**:\\n Define the purpose of the AI system, its intended use cases, and the stakeholders involved. This will help identify potential risks and benefits, as well as the necessary safeguards.\\n2. **Conduct Thorough Risk Assessments**:\\n Perform comprehensive risk assessments to understand potential threats and opportunities. Identify potential risks, such as data bias, bias in decision-making, or unintended consequences on society.\\n3. **Develop a Human-Centered Approach**:\\n Prioritize human needs, dignity, and well-being in AI system design. Ensure that the framework takes into account diverse cultural perspectives, values, and contexts to prevent cultural homogenization or exploitation.\\n4. **Foster Collaboration and Stakeholder Engagement**:\\n Engage with diverse stakeholders, including experts from various fields (e.g., ethics, law, sociology), industry representatives, policymakers, and community representatives to ensure that the AI system is aligned with societal values and needs.\\n5. **Incorporate Transparency and Explainability**:\\n Develop techniques to explain AI decision-making processes and provide transparent outputs. This will enable users to understand how AI systems make decisions and promote accountability.\\n6. **Emphasize Fairness, Accountability, and Resilience**:\\n Incorporate principles of fairness, accountability, and resilience into the framework. Ensure that AI systems are fair, unbiased, and resilient in the face of failures or cyber-attacks.\\n7. **Consider Socio-Economic Impacts**:\\n Assess potential socio-economic impacts, including job displacement, inequality, or amplification of existing biases. Develop mitigation strategies to minimize these effects.\\n8. **Establish Robust Auditing and Monitoring Processes**:\\n Regularly audit and monitor AI systems for compliance with the framework's principles and ensure that necessary safeguards are in place.\\n9. **Continuously Evaluate and Update the Framework**:\\n Regularly review and update the framework to address emerging challenges, technical advancements, or new societal values.\\n10. **Promote Public Engagement and Education**:\\n Educate stakeholders and the public about AI-related issues and promote informed discussions on AI development and deployment.\\n\\nSome additional considerations:\\n\\n*   **Accountability Mechanisms**: Establish accountability mechanisms for AI system developers, users, and regulators to ensure that the framework is enforced and respected.\\n*   **Global Harmonization**: Foster international cooperation to develop harmonized standards for AI ethics and governance, ensuring consistency across borders.\\n*   **Research and Development**: Support ongoing research and development to improve understanding of AI systems' potential risks and benefits.\\n\\nBy incorporating these elements into an ethical framework for AI systems, we can ensure that innovation is balanced with safety, diversity, and socio-economic considerations.\"]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.153031Z",
     "start_time": "2025-08-21T09:02:41.151180Z"
    }
   },
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini-2024-07-18\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, involves a multi-faceted approach. Here’s how I would approach this task:\n",
      "\n",
      "### 1. **Stakeholder Engagement**\n",
      "   - **Inclusivity**: Engage a diverse group of stakeholders, including technologists, ethicists, sociologists, policymakers, business leaders, and community representatives from different cultural backgrounds.\n",
      "   - **Public Consultation**: Conduct workshops, surveys, and focus groups to capture a wide range of views and concerns. This will help ensure the framework reflects various cultural perspectives and socio-economic contexts.\n",
      "\n",
      "### 2. **Core Principles Development**\n",
      "   - **Transparency**: Ensure that AI systems are built on transparent processes that allow stakeholders to understand how decisions are made.\n",
      "   - **Accountability**: Define clear accountability mechanisms for the development and deployment of AI technologies, including who is responsible when things go wrong.\n",
      "   - **Fairness and Non-discrimination**: Ensure that AI systems do not perpetuate biases or inequities. This includes ongoing audits for fairness and active measures to avoid discrimination across different socio-economic groups.\n",
      "   - **Safety and Security**: Incorporate risk assessment protocols that prioritize the safety and security of users and sensitive data.\n",
      "\n",
      "### 3. **Cultural Sensitivity**\n",
      "   - **Culturally Adaptive Standards**: Develop guidelines that allow for flexibility in implementation based on cultural norms and values, acknowledging that ethical considerations can differ across societies.\n",
      "   - **Global Collaboration**: Encourage international partnerships to share best practices and learn from various cultural frameworks surrounding AI ethics.\n",
      "\n",
      "### 4. **Regulatory and Policy Framework**\n",
      "   - **Collaborative Standards**: Work with regulatory bodies to create adaptable policy frameworks that promote responsible AI innovation while ensuring safety protocols are met.\n",
      "   - **Sandbox Environments**: Establish “regulatory sandboxes” where innovative AI applications can be tested in controlled environments, allowing for iterative learning and adjustment without risking public harm.\n",
      "\n",
      "### 5. **Impact Assessment and Monitoring**\n",
      "   - **Socio-economic Impact Assessments**: Require assessments to evaluate the potential socio-economic impacts of AI technologies, considering both positive and negative outcomes.\n",
      "   - **Continuous Monitoring**: Implement ongoing monitoring mechanisms to assess the real-world impacts of AI systems post-deployment and adapt the framework as necessary.\n",
      "\n",
      "### 6. **Education and Awareness**\n",
      "   - **Public Awareness Campaigns**: Develop initiatives to educate the public about AI technologies and their potential impacts, fostering an informed citizenry that can engage in ethical discussions.\n",
      "   - **Training for Stakeholders**: Provide training programs for developers, companies, and public officials on ethical AI principles, cultural sensitivity, and the socio-economic implications of AI technologies.\n",
      "\n",
      "### 7. **Research and Development Support**\n",
      "   - **Innovation Incentives**: Promote R&D that seeks to strike the balance between safety and innovation, potentially through grants or funding for projects that prioritize ethical considerations.\n",
      "   - **Cross-disciplinary Collaboration**: Encourage collaboration among computer scientists, social scientists, and humanities scholars to explore the societal impact of AI and inform ethical standards.\n",
      "\n",
      "### Conclusion\n",
      "The creation of an ethical framework for AI requires a comprehensive and adaptable approach that values diverse perspectives, addresses socio-economic realities, and balances the urgency for innovation with the necessity of safety. Continuous dialogue, stakeholder engagement, and an emphasis on education will be key to fostering responsible AI that benefits society as a whole.\n",
      "Competitor: claude-3-7-sonnet@20250219\n",
      "\n",
      "# Designing an Ethical Framework for AI Systems\n",
      "\n",
      "I'd approach this multifaceted challenge through these interconnected elements:\n",
      "\n",
      "## Core Principles\n",
      "- Establish universal baseline principles (safety, fairness, transparency) while allowing flexibility for cultural contexts\n",
      "- Implement tiered ethics requirements proportional to an AI system's potential impact\n",
      "- Ensure the framework evolves alongside technological advancement\n",
      "\n",
      "## Inclusive Development Process\n",
      "- Form a diverse global working group representing varied disciplines, cultures, and socioeconomic perspectives\n",
      "- Include historically marginalized voices and non-Western ethical traditions\n",
      "- Create feedback mechanisms to capture real-world impacts across different communities\n",
      "\n",
      "## Practical Implementation\n",
      "- Develop concrete guidelines for translating abstract principles into technical specifications\n",
      "- Require impact assessments examining potential harm to vulnerable populations\n",
      "- Establish governance mechanisms with meaningful oversight and accountability\n",
      "\n",
      "## Balancing Innovation and Safety\n",
      "- Create regulatory sandboxes where higher-risk innovations can be tested in controlled environments\n",
      "- Design graduated regulatory responses based on risk assessment\n",
      "- Focus restrictions on applications rather than foundational research\n",
      "\n",
      "What aspect of this framework would you like me to elaborate on further?\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts is a complex and multi-faceted challenge. Here's a comprehensive approach:\n",
      "\n",
      "**I. Core Principles and Values:**\n",
      "\n",
      "*   **Human-centricity:** Prioritize human well-being, autonomy, and dignity above all else. AI should serve humanity, not the other way around.\n",
      "*   **Beneficence and Non-maleficence:**  AI systems should strive to maximize positive impact and minimize harm.  This includes physical, psychological, economic, and social harms.\n",
      "*   **Fairness and Justice:** Ensure equitable access to AI benefits and equitable distribution of AI-related risks, avoiding discrimination and bias.\n",
      "*   **Transparency and Explainability:** AI systems should be understandable and their decision-making processes should be transparent where possible, allowing for accountability and redress.\n",
      "*   **Privacy and Data Security:**  Protect individuals' privacy and ensure the secure handling of data used by AI systems. Implement strong data governance principles.\n",
      "*   **Accountability:** Establish clear lines of responsibility for the development, deployment, and consequences of AI systems.\n",
      "*   **Sustainability:** Consider the environmental impact of AI development and deployment, promoting sustainable practices.\n",
      "*   **Respect for Human Rights:** Ensure AI systems are designed and used in a manner that respects all human rights, including freedom of speech, expression, and assembly.\n",
      "*   **Cultural Sensitivity:** Acknowledge and address the diverse cultural values, beliefs, and norms that may be impacted by AI systems.\n",
      "\n",
      "**II. Stakeholder Engagement and Consultation:**\n",
      "\n",
      "*   **Involve diverse voices:**  Engage a broad range of stakeholders, including:\n",
      "    *   AI developers and researchers\n",
      "    *   Ethicists and philosophers\n",
      "    *   Legal experts\n",
      "    *   Policymakers and regulators\n",
      "    *   Civil society organizations\n",
      "    *   Affected communities (including marginalized and vulnerable groups)\n",
      "    *   Businesses and industry representatives\n",
      "*   **Global perspective:**  Solicit input from individuals and organizations from different countries and cultures to ensure inclusivity and avoid Western-centric biases.\n",
      "*   **Consultation methods:**  Utilize a variety of methods for gathering input, such as:\n",
      "    *   Public forums and workshops\n",
      "    *   Surveys and questionnaires\n",
      "    *   Focus groups\n",
      "    *   Online platforms for feedback\n",
      "    *   Expert panels and advisory boards\n",
      "*   **Iterative process:**  Continuously refine the ethical framework based on stakeholder feedback and evolving AI technologies.\n",
      "\n",
      "**III. Framework Components:**\n",
      "\n",
      "1.  **Ethical Guidelines for AI Development:**\n",
      "\n",
      "    *   **Bias detection and mitigation:** Implement techniques to identify and address biases in data and algorithms.  This includes using diverse datasets and fairness-aware algorithms.\n",
      "    *   **Explainability methods:**  Employ methods to make AI decision-making more understandable, such as SHAP values, LIME, and counterfactual explanations.\n",
      "    *   **Privacy-preserving techniques:**  Utilize techniques like differential privacy, federated learning, and homomorphic encryption to protect user data.\n",
      "    *   **Security protocols:**  Implement robust security measures to prevent malicious use of AI systems and protect against data breaches.\n",
      "    *   **Testing and validation:**  Thoroughly test and validate AI systems to ensure they are safe, reliable, and perform as expected. This includes adversarial testing and stress testing.\n",
      "    *   **Monitoring and auditing:** Continuously monitor AI systems for unintended consequences and audit their performance for fairness and accuracy.\n",
      "    *   **Documentation:**  Maintain comprehensive documentation of the AI system's design, development, and deployment, including ethical considerations and risk assessments.\n",
      "    *   **Human oversight:**  Establish mechanisms for human oversight and intervention in AI decision-making processes, especially in high-stakes applications.\n",
      "\n",
      "2.  **Ethical Framework for AI Deployment:**\n",
      "\n",
      "    *   **Impact assessment:** Conduct thorough impact assessments before deploying AI systems, considering potential social, economic, and environmental consequences.\n",
      "    *   **Transparency with users:**  Clearly communicate to users how AI systems are being used and how they might affect them.\n",
      "    *   **User control:**  Empower users with control over their data and the ability to opt-out of AI-driven services.\n",
      "    *   **Redress mechanisms:**  Establish mechanisms for individuals to seek redress if they are harmed by an AI system. This could include dispute resolution processes and legal remedies.\n",
      "    *   **Skill development and job transition programs:** Implement programs to support workers who may be displaced by AI-driven automation.\n",
      "    *   **Regulation and governance:**  Develop appropriate regulatory frameworks to govern the development and deployment of AI, balancing innovation with safety and ethical considerations.  These regulations may need to vary across sectors.\n",
      "    *   **International cooperation:**  Promote international collaboration and harmonization of ethical standards for AI.\n",
      "\n",
      "3.  **Addressing Socio-Economic Impacts:**\n",
      "\n",
      "    *   **Economic inequality:** Implement policies to address the potential for AI to exacerbate economic inequality, such as progressive taxation, universal basic income, and investment in education and training.\n",
      "    *   **Job displacement:**  Invest in retraining programs and create new job opportunities in emerging fields. Explore alternative work arrangements, such as shorter workweeks and job sharing.\n",
      "    *   **Access to technology:**  Ensure equitable access to AI-driven technologies and services, especially for underserved communities.\n",
      "    *   **Digital literacy:**  Promote digital literacy skills to empower individuals to use AI-powered tools and services effectively.\n",
      "    *   **Fair competition:**  Foster fair competition in the AI market to prevent monopolies and promote innovation.\n",
      "\n",
      "4.  **Addressing Cultural Considerations:**\n",
      "\n",
      "    *   **Cultural sensitivity training:**  Provide cultural sensitivity training to AI developers and policymakers.\n",
      "    *   **Localization:**  Adapt AI systems to local languages, cultural norms, and values.\n",
      "    *   **Participatory design:**  Involve local communities in the design and development of AI systems to ensure they are culturally appropriate.\n",
      "    *   **Respect for cultural heritage:**  Protect cultural heritage from potential harm caused by AI systems, such as the spread of misinformation or the appropriation of cultural artifacts.\n",
      "    *   **Recognize diverse perspectives:**  Acknowledge that ethical considerations may vary across cultures and avoid imposing a single, universal ethical framework.\n",
      "    *   **Promote cross-cultural dialogue:**  Facilitate dialogue and collaboration between different cultures to foster a shared understanding of ethical AI.\n",
      "\n",
      "**IV. Implementation and Enforcement:**\n",
      "\n",
      "*   **Self-regulation:** Encourage industry self-regulation through the development of ethical codes of conduct and best practices.\n",
      "*   **Certification and auditing:**  Establish certification and auditing programs to ensure that AI systems meet ethical standards.\n",
      "*   **Regulatory oversight:**  Implement regulatory oversight and enforcement mechanisms to address egregious violations of ethical principles.\n",
      "*   **Liability frameworks:**  Clarify liability frameworks for harms caused by AI systems.\n",
      "*   **Education and awareness:**  Promote education and awareness of ethical issues in AI among the general public.\n",
      "\n",
      "**V. Ongoing Review and Adaptation:**\n",
      "\n",
      "*   **Regular evaluation:**  Regularly evaluate the effectiveness of the ethical framework and make adjustments as needed to reflect technological advancements and evolving societal values.\n",
      "*   **Continuous learning:**  Stay abreast of the latest research and best practices in ethical AI.\n",
      "*   **Adaptable framework:**  Design the framework to be flexible and adaptable to new challenges and opportunities presented by AI.\n",
      "\n",
      "**Key Considerations for Success:**\n",
      "\n",
      "*   **Strong leadership:**  Effective leadership is crucial to drive the development and implementation of the ethical framework.\n",
      "*   **Collaboration and coordination:**  Collaboration and coordination among stakeholders are essential for building consensus and ensuring that the framework is effectively implemented.\n",
      "*   **Resources:**  Adequate resources are needed to support research, development, and implementation of ethical AI practices.\n",
      "*   **Political will:**  Political will is needed to enact and enforce regulations and policies that promote ethical AI.\n",
      "*   **Public trust:** Building and maintaining public trust in AI is essential for its widespread adoption and acceptance.\n",
      "\n",
      "By following this comprehensive approach, we can create an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, ultimately ensuring that AI serves humanity in a responsible and beneficial way. It's a continuous journey, requiring vigilance, adaptation, and a commitment to ethical principles.\n",
      "\n",
      "Competitor: llama3.2\n",
      "\n",
      "Designing an ethical framework for AI systems requires a multidisciplinary approach that considers various factors, including technical, social, and economic aspects. Here's a comprehensive framework to balance innovation with safety, diversity, and socio-economic considerations:\n",
      "\n",
      "1. **Establish a Clear Purpose and Scope**:\n",
      " Define the purpose of the AI system, its intended use cases, and the stakeholders involved. This will help identify potential risks and benefits, as well as the necessary safeguards.\n",
      "2. **Conduct Thorough Risk Assessments**:\n",
      " Perform comprehensive risk assessments to understand potential threats and opportunities. Identify potential risks, such as data bias, bias in decision-making, or unintended consequences on society.\n",
      "3. **Develop a Human-Centered Approach**:\n",
      " Prioritize human needs, dignity, and well-being in AI system design. Ensure that the framework takes into account diverse cultural perspectives, values, and contexts to prevent cultural homogenization or exploitation.\n",
      "4. **Foster Collaboration and Stakeholder Engagement**:\n",
      " Engage with diverse stakeholders, including experts from various fields (e.g., ethics, law, sociology), industry representatives, policymakers, and community representatives to ensure that the AI system is aligned with societal values and needs.\n",
      "5. **Incorporate Transparency and Explainability**:\n",
      " Develop techniques to explain AI decision-making processes and provide transparent outputs. This will enable users to understand how AI systems make decisions and promote accountability.\n",
      "6. **Emphasize Fairness, Accountability, and Resilience**:\n",
      " Incorporate principles of fairness, accountability, and resilience into the framework. Ensure that AI systems are fair, unbiased, and resilient in the face of failures or cyber-attacks.\n",
      "7. **Consider Socio-Economic Impacts**:\n",
      " Assess potential socio-economic impacts, including job displacement, inequality, or amplification of existing biases. Develop mitigation strategies to minimize these effects.\n",
      "8. **Establish Robust Auditing and Monitoring Processes**:\n",
      " Regularly audit and monitor AI systems for compliance with the framework's principles and ensure that necessary safeguards are in place.\n",
      "9. **Continuously Evaluate and Update the Framework**:\n",
      " Regularly review and update the framework to address emerging challenges, technical advancements, or new societal values.\n",
      "10. **Promote Public Engagement and Education**:\n",
      " Educate stakeholders and the public about AI-related issues and promote informed discussions on AI development and deployment.\n",
      "\n",
      "Some additional considerations:\n",
      "\n",
      "*   **Accountability Mechanisms**: Establish accountability mechanisms for AI system developers, users, and regulators to ensure that the framework is enforced and respected.\n",
      "*   **Global Harmonization**: Foster international cooperation to develop harmonized standards for AI ethics and governance, ensuring consistency across borders.\n",
      "*   **Research and Development**: Support ongoing research and development to improve understanding of AI systems' potential risks and benefits.\n",
      "\n",
      "By incorporating these elements into an ethical framework for AI systems, we can ensure that innovation is balanced with safety, diversity, and socio-economic considerations.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.165700Z",
     "start_time": "2025-08-21T09:02:41.164028Z"
    }
   },
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.175902Z",
     "start_time": "2025-08-21T09:02:41.174359Z"
    }
   },
   "source": [
    "print(together)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, involves a multi-faceted approach. Here’s how I would approach this task:\n",
      "\n",
      "### 1. **Stakeholder Engagement**\n",
      "   - **Inclusivity**: Engage a diverse group of stakeholders, including technologists, ethicists, sociologists, policymakers, business leaders, and community representatives from different cultural backgrounds.\n",
      "   - **Public Consultation**: Conduct workshops, surveys, and focus groups to capture a wide range of views and concerns. This will help ensure the framework reflects various cultural perspectives and socio-economic contexts.\n",
      "\n",
      "### 2. **Core Principles Development**\n",
      "   - **Transparency**: Ensure that AI systems are built on transparent processes that allow stakeholders to understand how decisions are made.\n",
      "   - **Accountability**: Define clear accountability mechanisms for the development and deployment of AI technologies, including who is responsible when things go wrong.\n",
      "   - **Fairness and Non-discrimination**: Ensure that AI systems do not perpetuate biases or inequities. This includes ongoing audits for fairness and active measures to avoid discrimination across different socio-economic groups.\n",
      "   - **Safety and Security**: Incorporate risk assessment protocols that prioritize the safety and security of users and sensitive data.\n",
      "\n",
      "### 3. **Cultural Sensitivity**\n",
      "   - **Culturally Adaptive Standards**: Develop guidelines that allow for flexibility in implementation based on cultural norms and values, acknowledging that ethical considerations can differ across societies.\n",
      "   - **Global Collaboration**: Encourage international partnerships to share best practices and learn from various cultural frameworks surrounding AI ethics.\n",
      "\n",
      "### 4. **Regulatory and Policy Framework**\n",
      "   - **Collaborative Standards**: Work with regulatory bodies to create adaptable policy frameworks that promote responsible AI innovation while ensuring safety protocols are met.\n",
      "   - **Sandbox Environments**: Establish “regulatory sandboxes” where innovative AI applications can be tested in controlled environments, allowing for iterative learning and adjustment without risking public harm.\n",
      "\n",
      "### 5. **Impact Assessment and Monitoring**\n",
      "   - **Socio-economic Impact Assessments**: Require assessments to evaluate the potential socio-economic impacts of AI technologies, considering both positive and negative outcomes.\n",
      "   - **Continuous Monitoring**: Implement ongoing monitoring mechanisms to assess the real-world impacts of AI systems post-deployment and adapt the framework as necessary.\n",
      "\n",
      "### 6. **Education and Awareness**\n",
      "   - **Public Awareness Campaigns**: Develop initiatives to educate the public about AI technologies and their potential impacts, fostering an informed citizenry that can engage in ethical discussions.\n",
      "   - **Training for Stakeholders**: Provide training programs for developers, companies, and public officials on ethical AI principles, cultural sensitivity, and the socio-economic implications of AI technologies.\n",
      "\n",
      "### 7. **Research and Development Support**\n",
      "   - **Innovation Incentives**: Promote R&D that seeks to strike the balance between safety and innovation, potentially through grants or funding for projects that prioritize ethical considerations.\n",
      "   - **Cross-disciplinary Collaboration**: Encourage collaboration among computer scientists, social scientists, and humanities scholars to explore the societal impact of AI and inform ethical standards.\n",
      "\n",
      "### Conclusion\n",
      "The creation of an ethical framework for AI requires a comprehensive and adaptable approach that values diverse perspectives, addresses socio-economic realities, and balances the urgency for innovation with the necessity of safety. Continuous dialogue, stakeholder engagement, and an emphasis on education will be key to fostering responsible AI that benefits society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Designing an Ethical Framework for AI Systems\n",
      "\n",
      "I'd approach this multifaceted challenge through these interconnected elements:\n",
      "\n",
      "## Core Principles\n",
      "- Establish universal baseline principles (safety, fairness, transparency) while allowing flexibility for cultural contexts\n",
      "- Implement tiered ethics requirements proportional to an AI system's potential impact\n",
      "- Ensure the framework evolves alongside technological advancement\n",
      "\n",
      "## Inclusive Development Process\n",
      "- Form a diverse global working group representing varied disciplines, cultures, and socioeconomic perspectives\n",
      "- Include historically marginalized voices and non-Western ethical traditions\n",
      "- Create feedback mechanisms to capture real-world impacts across different communities\n",
      "\n",
      "## Practical Implementation\n",
      "- Develop concrete guidelines for translating abstract principles into technical specifications\n",
      "- Require impact assessments examining potential harm to vulnerable populations\n",
      "- Establish governance mechanisms with meaningful oversight and accountability\n",
      "\n",
      "## Balancing Innovation and Safety\n",
      "- Create regulatory sandboxes where higher-risk innovations can be tested in controlled environments\n",
      "- Design graduated regulatory responses based on risk assessment\n",
      "- Focus restrictions on applications rather than foundational research\n",
      "\n",
      "What aspect of this framework would you like me to elaborate on further?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts is a complex and multi-faceted challenge. Here's a comprehensive approach:\n",
      "\n",
      "**I. Core Principles and Values:**\n",
      "\n",
      "*   **Human-centricity:** Prioritize human well-being, autonomy, and dignity above all else. AI should serve humanity, not the other way around.\n",
      "*   **Beneficence and Non-maleficence:**  AI systems should strive to maximize positive impact and minimize harm.  This includes physical, psychological, economic, and social harms.\n",
      "*   **Fairness and Justice:** Ensure equitable access to AI benefits and equitable distribution of AI-related risks, avoiding discrimination and bias.\n",
      "*   **Transparency and Explainability:** AI systems should be understandable and their decision-making processes should be transparent where possible, allowing for accountability and redress.\n",
      "*   **Privacy and Data Security:**  Protect individuals' privacy and ensure the secure handling of data used by AI systems. Implement strong data governance principles.\n",
      "*   **Accountability:** Establish clear lines of responsibility for the development, deployment, and consequences of AI systems.\n",
      "*   **Sustainability:** Consider the environmental impact of AI development and deployment, promoting sustainable practices.\n",
      "*   **Respect for Human Rights:** Ensure AI systems are designed and used in a manner that respects all human rights, including freedom of speech, expression, and assembly.\n",
      "*   **Cultural Sensitivity:** Acknowledge and address the diverse cultural values, beliefs, and norms that may be impacted by AI systems.\n",
      "\n",
      "**II. Stakeholder Engagement and Consultation:**\n",
      "\n",
      "*   **Involve diverse voices:**  Engage a broad range of stakeholders, including:\n",
      "    *   AI developers and researchers\n",
      "    *   Ethicists and philosophers\n",
      "    *   Legal experts\n",
      "    *   Policymakers and regulators\n",
      "    *   Civil society organizations\n",
      "    *   Affected communities (including marginalized and vulnerable groups)\n",
      "    *   Businesses and industry representatives\n",
      "*   **Global perspective:**  Solicit input from individuals and organizations from different countries and cultures to ensure inclusivity and avoid Western-centric biases.\n",
      "*   **Consultation methods:**  Utilize a variety of methods for gathering input, such as:\n",
      "    *   Public forums and workshops\n",
      "    *   Surveys and questionnaires\n",
      "    *   Focus groups\n",
      "    *   Online platforms for feedback\n",
      "    *   Expert panels and advisory boards\n",
      "*   **Iterative process:**  Continuously refine the ethical framework based on stakeholder feedback and evolving AI technologies.\n",
      "\n",
      "**III. Framework Components:**\n",
      "\n",
      "1.  **Ethical Guidelines for AI Development:**\n",
      "\n",
      "    *   **Bias detection and mitigation:** Implement techniques to identify and address biases in data and algorithms.  This includes using diverse datasets and fairness-aware algorithms.\n",
      "    *   **Explainability methods:**  Employ methods to make AI decision-making more understandable, such as SHAP values, LIME, and counterfactual explanations.\n",
      "    *   **Privacy-preserving techniques:**  Utilize techniques like differential privacy, federated learning, and homomorphic encryption to protect user data.\n",
      "    *   **Security protocols:**  Implement robust security measures to prevent malicious use of AI systems and protect against data breaches.\n",
      "    *   **Testing and validation:**  Thoroughly test and validate AI systems to ensure they are safe, reliable, and perform as expected. This includes adversarial testing and stress testing.\n",
      "    *   **Monitoring and auditing:** Continuously monitor AI systems for unintended consequences and audit their performance for fairness and accuracy.\n",
      "    *   **Documentation:**  Maintain comprehensive documentation of the AI system's design, development, and deployment, including ethical considerations and risk assessments.\n",
      "    *   **Human oversight:**  Establish mechanisms for human oversight and intervention in AI decision-making processes, especially in high-stakes applications.\n",
      "\n",
      "2.  **Ethical Framework for AI Deployment:**\n",
      "\n",
      "    *   **Impact assessment:** Conduct thorough impact assessments before deploying AI systems, considering potential social, economic, and environmental consequences.\n",
      "    *   **Transparency with users:**  Clearly communicate to users how AI systems are being used and how they might affect them.\n",
      "    *   **User control:**  Empower users with control over their data and the ability to opt-out of AI-driven services.\n",
      "    *   **Redress mechanisms:**  Establish mechanisms for individuals to seek redress if they are harmed by an AI system. This could include dispute resolution processes and legal remedies.\n",
      "    *   **Skill development and job transition programs:** Implement programs to support workers who may be displaced by AI-driven automation.\n",
      "    *   **Regulation and governance:**  Develop appropriate regulatory frameworks to govern the development and deployment of AI, balancing innovation with safety and ethical considerations.  These regulations may need to vary across sectors.\n",
      "    *   **International cooperation:**  Promote international collaboration and harmonization of ethical standards for AI.\n",
      "\n",
      "3.  **Addressing Socio-Economic Impacts:**\n",
      "\n",
      "    *   **Economic inequality:** Implement policies to address the potential for AI to exacerbate economic inequality, such as progressive taxation, universal basic income, and investment in education and training.\n",
      "    *   **Job displacement:**  Invest in retraining programs and create new job opportunities in emerging fields. Explore alternative work arrangements, such as shorter workweeks and job sharing.\n",
      "    *   **Access to technology:**  Ensure equitable access to AI-driven technologies and services, especially for underserved communities.\n",
      "    *   **Digital literacy:**  Promote digital literacy skills to empower individuals to use AI-powered tools and services effectively.\n",
      "    *   **Fair competition:**  Foster fair competition in the AI market to prevent monopolies and promote innovation.\n",
      "\n",
      "4.  **Addressing Cultural Considerations:**\n",
      "\n",
      "    *   **Cultural sensitivity training:**  Provide cultural sensitivity training to AI developers and policymakers.\n",
      "    *   **Localization:**  Adapt AI systems to local languages, cultural norms, and values.\n",
      "    *   **Participatory design:**  Involve local communities in the design and development of AI systems to ensure they are culturally appropriate.\n",
      "    *   **Respect for cultural heritage:**  Protect cultural heritage from potential harm caused by AI systems, such as the spread of misinformation or the appropriation of cultural artifacts.\n",
      "    *   **Recognize diverse perspectives:**  Acknowledge that ethical considerations may vary across cultures and avoid imposing a single, universal ethical framework.\n",
      "    *   **Promote cross-cultural dialogue:**  Facilitate dialogue and collaboration between different cultures to foster a shared understanding of ethical AI.\n",
      "\n",
      "**IV. Implementation and Enforcement:**\n",
      "\n",
      "*   **Self-regulation:** Encourage industry self-regulation through the development of ethical codes of conduct and best practices.\n",
      "*   **Certification and auditing:**  Establish certification and auditing programs to ensure that AI systems meet ethical standards.\n",
      "*   **Regulatory oversight:**  Implement regulatory oversight and enforcement mechanisms to address egregious violations of ethical principles.\n",
      "*   **Liability frameworks:**  Clarify liability frameworks for harms caused by AI systems.\n",
      "*   **Education and awareness:**  Promote education and awareness of ethical issues in AI among the general public.\n",
      "\n",
      "**V. Ongoing Review and Adaptation:**\n",
      "\n",
      "*   **Regular evaluation:**  Regularly evaluate the effectiveness of the ethical framework and make adjustments as needed to reflect technological advancements and evolving societal values.\n",
      "*   **Continuous learning:**  Stay abreast of the latest research and best practices in ethical AI.\n",
      "*   **Adaptable framework:**  Design the framework to be flexible and adaptable to new challenges and opportunities presented by AI.\n",
      "\n",
      "**Key Considerations for Success:**\n",
      "\n",
      "*   **Strong leadership:**  Effective leadership is crucial to drive the development and implementation of the ethical framework.\n",
      "*   **Collaboration and coordination:**  Collaboration and coordination among stakeholders are essential for building consensus and ensuring that the framework is effectively implemented.\n",
      "*   **Resources:**  Adequate resources are needed to support research, development, and implementation of ethical AI practices.\n",
      "*   **Political will:**  Political will is needed to enact and enforce regulations and policies that promote ethical AI.\n",
      "*   **Public trust:** Building and maintaining public trust in AI is essential for its widespread adoption and acceptance.\n",
      "\n",
      "By following this comprehensive approach, we can create an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, ultimately ensuring that AI serves humanity in a responsible and beneficial way. It's a continuous journey, requiring vigilance, adaptation, and a commitment to ethical principles.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Designing an ethical framework for AI systems requires a multidisciplinary approach that considers various factors, including technical, social, and economic aspects. Here's a comprehensive framework to balance innovation with safety, diversity, and socio-economic considerations:\n",
      "\n",
      "1. **Establish a Clear Purpose and Scope**:\n",
      " Define the purpose of the AI system, its intended use cases, and the stakeholders involved. This will help identify potential risks and benefits, as well as the necessary safeguards.\n",
      "2. **Conduct Thorough Risk Assessments**:\n",
      " Perform comprehensive risk assessments to understand potential threats and opportunities. Identify potential risks, such as data bias, bias in decision-making, or unintended consequences on society.\n",
      "3. **Develop a Human-Centered Approach**:\n",
      " Prioritize human needs, dignity, and well-being in AI system design. Ensure that the framework takes into account diverse cultural perspectives, values, and contexts to prevent cultural homogenization or exploitation.\n",
      "4. **Foster Collaboration and Stakeholder Engagement**:\n",
      " Engage with diverse stakeholders, including experts from various fields (e.g., ethics, law, sociology), industry representatives, policymakers, and community representatives to ensure that the AI system is aligned with societal values and needs.\n",
      "5. **Incorporate Transparency and Explainability**:\n",
      " Develop techniques to explain AI decision-making processes and provide transparent outputs. This will enable users to understand how AI systems make decisions and promote accountability.\n",
      "6. **Emphasize Fairness, Accountability, and Resilience**:\n",
      " Incorporate principles of fairness, accountability, and resilience into the framework. Ensure that AI systems are fair, unbiased, and resilient in the face of failures or cyber-attacks.\n",
      "7. **Consider Socio-Economic Impacts**:\n",
      " Assess potential socio-economic impacts, including job displacement, inequality, or amplification of existing biases. Develop mitigation strategies to minimize these effects.\n",
      "8. **Establish Robust Auditing and Monitoring Processes**:\n",
      " Regularly audit and monitor AI systems for compliance with the framework's principles and ensure that necessary safeguards are in place.\n",
      "9. **Continuously Evaluate and Update the Framework**:\n",
      " Regularly review and update the framework to address emerging challenges, technical advancements, or new societal values.\n",
      "10. **Promote Public Engagement and Education**:\n",
      " Educate stakeholders and the public about AI-related issues and promote informed discussions on AI development and deployment.\n",
      "\n",
      "Some additional considerations:\n",
      "\n",
      "*   **Accountability Mechanisms**: Establish accountability mechanisms for AI system developers, users, and regulators to ensure that the framework is enforced and respected.\n",
      "*   **Global Harmonization**: Foster international cooperation to develop harmonized standards for AI ethics and governance, ensuring consistency across borders.\n",
      "*   **Research and Development**: Support ongoing research and development to improve understanding of AI systems' potential risks and benefits.\n",
      "\n",
      "By incorporating these elements into an ethical framework for AI systems, we can ensure that innovation is balanced with safety, diversity, and socio-economic considerations.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.185527Z",
     "start_time": "2025-08-21T09:02:41.183952Z"
    }
   },
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.194503Z",
     "start_time": "2025-08-21T09:02:41.192817Z"
    }
   },
   "source": [
    "print(judge)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 4 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you approach designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, involves a multi-faceted approach. Here’s how I would approach this task:\n",
      "\n",
      "### 1. **Stakeholder Engagement**\n",
      "   - **Inclusivity**: Engage a diverse group of stakeholders, including technologists, ethicists, sociologists, policymakers, business leaders, and community representatives from different cultural backgrounds.\n",
      "   - **Public Consultation**: Conduct workshops, surveys, and focus groups to capture a wide range of views and concerns. This will help ensure the framework reflects various cultural perspectives and socio-economic contexts.\n",
      "\n",
      "### 2. **Core Principles Development**\n",
      "   - **Transparency**: Ensure that AI systems are built on transparent processes that allow stakeholders to understand how decisions are made.\n",
      "   - **Accountability**: Define clear accountability mechanisms for the development and deployment of AI technologies, including who is responsible when things go wrong.\n",
      "   - **Fairness and Non-discrimination**: Ensure that AI systems do not perpetuate biases or inequities. This includes ongoing audits for fairness and active measures to avoid discrimination across different socio-economic groups.\n",
      "   - **Safety and Security**: Incorporate risk assessment protocols that prioritize the safety and security of users and sensitive data.\n",
      "\n",
      "### 3. **Cultural Sensitivity**\n",
      "   - **Culturally Adaptive Standards**: Develop guidelines that allow for flexibility in implementation based on cultural norms and values, acknowledging that ethical considerations can differ across societies.\n",
      "   - **Global Collaboration**: Encourage international partnerships to share best practices and learn from various cultural frameworks surrounding AI ethics.\n",
      "\n",
      "### 4. **Regulatory and Policy Framework**\n",
      "   - **Collaborative Standards**: Work with regulatory bodies to create adaptable policy frameworks that promote responsible AI innovation while ensuring safety protocols are met.\n",
      "   - **Sandbox Environments**: Establish “regulatory sandboxes” where innovative AI applications can be tested in controlled environments, allowing for iterative learning and adjustment without risking public harm.\n",
      "\n",
      "### 5. **Impact Assessment and Monitoring**\n",
      "   - **Socio-economic Impact Assessments**: Require assessments to evaluate the potential socio-economic impacts of AI technologies, considering both positive and negative outcomes.\n",
      "   - **Continuous Monitoring**: Implement ongoing monitoring mechanisms to assess the real-world impacts of AI systems post-deployment and adapt the framework as necessary.\n",
      "\n",
      "### 6. **Education and Awareness**\n",
      "   - **Public Awareness Campaigns**: Develop initiatives to educate the public about AI technologies and their potential impacts, fostering an informed citizenry that can engage in ethical discussions.\n",
      "   - **Training for Stakeholders**: Provide training programs for developers, companies, and public officials on ethical AI principles, cultural sensitivity, and the socio-economic implications of AI technologies.\n",
      "\n",
      "### 7. **Research and Development Support**\n",
      "   - **Innovation Incentives**: Promote R&D that seeks to strike the balance between safety and innovation, potentially through grants or funding for projects that prioritize ethical considerations.\n",
      "   - **Cross-disciplinary Collaboration**: Encourage collaboration among computer scientists, social scientists, and humanities scholars to explore the societal impact of AI and inform ethical standards.\n",
      "\n",
      "### Conclusion\n",
      "The creation of an ethical framework for AI requires a comprehensive and adaptable approach that values diverse perspectives, addresses socio-economic realities, and balances the urgency for innovation with the necessity of safety. Continuous dialogue, stakeholder engagement, and an emphasis on education will be key to fostering responsible AI that benefits society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Designing an Ethical Framework for AI Systems\n",
      "\n",
      "I'd approach this multifaceted challenge through these interconnected elements:\n",
      "\n",
      "## Core Principles\n",
      "- Establish universal baseline principles (safety, fairness, transparency) while allowing flexibility for cultural contexts\n",
      "- Implement tiered ethics requirements proportional to an AI system's potential impact\n",
      "- Ensure the framework evolves alongside technological advancement\n",
      "\n",
      "## Inclusive Development Process\n",
      "- Form a diverse global working group representing varied disciplines, cultures, and socioeconomic perspectives\n",
      "- Include historically marginalized voices and non-Western ethical traditions\n",
      "- Create feedback mechanisms to capture real-world impacts across different communities\n",
      "\n",
      "## Practical Implementation\n",
      "- Develop concrete guidelines for translating abstract principles into technical specifications\n",
      "- Require impact assessments examining potential harm to vulnerable populations\n",
      "- Establish governance mechanisms with meaningful oversight and accountability\n",
      "\n",
      "## Balancing Innovation and Safety\n",
      "- Create regulatory sandboxes where higher-risk innovations can be tested in controlled environments\n",
      "- Design graduated regulatory responses based on risk assessment\n",
      "- Focus restrictions on applications rather than foundational research\n",
      "\n",
      "What aspect of this framework would you like me to elaborate on further?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Designing an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts is a complex and multi-faceted challenge. Here's a comprehensive approach:\n",
      "\n",
      "**I. Core Principles and Values:**\n",
      "\n",
      "*   **Human-centricity:** Prioritize human well-being, autonomy, and dignity above all else. AI should serve humanity, not the other way around.\n",
      "*   **Beneficence and Non-maleficence:**  AI systems should strive to maximize positive impact and minimize harm.  This includes physical, psychological, economic, and social harms.\n",
      "*   **Fairness and Justice:** Ensure equitable access to AI benefits and equitable distribution of AI-related risks, avoiding discrimination and bias.\n",
      "*   **Transparency and Explainability:** AI systems should be understandable and their decision-making processes should be transparent where possible, allowing for accountability and redress.\n",
      "*   **Privacy and Data Security:**  Protect individuals' privacy and ensure the secure handling of data used by AI systems. Implement strong data governance principles.\n",
      "*   **Accountability:** Establish clear lines of responsibility for the development, deployment, and consequences of AI systems.\n",
      "*   **Sustainability:** Consider the environmental impact of AI development and deployment, promoting sustainable practices.\n",
      "*   **Respect for Human Rights:** Ensure AI systems are designed and used in a manner that respects all human rights, including freedom of speech, expression, and assembly.\n",
      "*   **Cultural Sensitivity:** Acknowledge and address the diverse cultural values, beliefs, and norms that may be impacted by AI systems.\n",
      "\n",
      "**II. Stakeholder Engagement and Consultation:**\n",
      "\n",
      "*   **Involve diverse voices:**  Engage a broad range of stakeholders, including:\n",
      "    *   AI developers and researchers\n",
      "    *   Ethicists and philosophers\n",
      "    *   Legal experts\n",
      "    *   Policymakers and regulators\n",
      "    *   Civil society organizations\n",
      "    *   Affected communities (including marginalized and vulnerable groups)\n",
      "    *   Businesses and industry representatives\n",
      "*   **Global perspective:**  Solicit input from individuals and organizations from different countries and cultures to ensure inclusivity and avoid Western-centric biases.\n",
      "*   **Consultation methods:**  Utilize a variety of methods for gathering input, such as:\n",
      "    *   Public forums and workshops\n",
      "    *   Surveys and questionnaires\n",
      "    *   Focus groups\n",
      "    *   Online platforms for feedback\n",
      "    *   Expert panels and advisory boards\n",
      "*   **Iterative process:**  Continuously refine the ethical framework based on stakeholder feedback and evolving AI technologies.\n",
      "\n",
      "**III. Framework Components:**\n",
      "\n",
      "1.  **Ethical Guidelines for AI Development:**\n",
      "\n",
      "    *   **Bias detection and mitigation:** Implement techniques to identify and address biases in data and algorithms.  This includes using diverse datasets and fairness-aware algorithms.\n",
      "    *   **Explainability methods:**  Employ methods to make AI decision-making more understandable, such as SHAP values, LIME, and counterfactual explanations.\n",
      "    *   **Privacy-preserving techniques:**  Utilize techniques like differential privacy, federated learning, and homomorphic encryption to protect user data.\n",
      "    *   **Security protocols:**  Implement robust security measures to prevent malicious use of AI systems and protect against data breaches.\n",
      "    *   **Testing and validation:**  Thoroughly test and validate AI systems to ensure they are safe, reliable, and perform as expected. This includes adversarial testing and stress testing.\n",
      "    *   **Monitoring and auditing:** Continuously monitor AI systems for unintended consequences and audit their performance for fairness and accuracy.\n",
      "    *   **Documentation:**  Maintain comprehensive documentation of the AI system's design, development, and deployment, including ethical considerations and risk assessments.\n",
      "    *   **Human oversight:**  Establish mechanisms for human oversight and intervention in AI decision-making processes, especially in high-stakes applications.\n",
      "\n",
      "2.  **Ethical Framework for AI Deployment:**\n",
      "\n",
      "    *   **Impact assessment:** Conduct thorough impact assessments before deploying AI systems, considering potential social, economic, and environmental consequences.\n",
      "    *   **Transparency with users:**  Clearly communicate to users how AI systems are being used and how they might affect them.\n",
      "    *   **User control:**  Empower users with control over their data and the ability to opt-out of AI-driven services.\n",
      "    *   **Redress mechanisms:**  Establish mechanisms for individuals to seek redress if they are harmed by an AI system. This could include dispute resolution processes and legal remedies.\n",
      "    *   **Skill development and job transition programs:** Implement programs to support workers who may be displaced by AI-driven automation.\n",
      "    *   **Regulation and governance:**  Develop appropriate regulatory frameworks to govern the development and deployment of AI, balancing innovation with safety and ethical considerations.  These regulations may need to vary across sectors.\n",
      "    *   **International cooperation:**  Promote international collaboration and harmonization of ethical standards for AI.\n",
      "\n",
      "3.  **Addressing Socio-Economic Impacts:**\n",
      "\n",
      "    *   **Economic inequality:** Implement policies to address the potential for AI to exacerbate economic inequality, such as progressive taxation, universal basic income, and investment in education and training.\n",
      "    *   **Job displacement:**  Invest in retraining programs and create new job opportunities in emerging fields. Explore alternative work arrangements, such as shorter workweeks and job sharing.\n",
      "    *   **Access to technology:**  Ensure equitable access to AI-driven technologies and services, especially for underserved communities.\n",
      "    *   **Digital literacy:**  Promote digital literacy skills to empower individuals to use AI-powered tools and services effectively.\n",
      "    *   **Fair competition:**  Foster fair competition in the AI market to prevent monopolies and promote innovation.\n",
      "\n",
      "4.  **Addressing Cultural Considerations:**\n",
      "\n",
      "    *   **Cultural sensitivity training:**  Provide cultural sensitivity training to AI developers and policymakers.\n",
      "    *   **Localization:**  Adapt AI systems to local languages, cultural norms, and values.\n",
      "    *   **Participatory design:**  Involve local communities in the design and development of AI systems to ensure they are culturally appropriate.\n",
      "    *   **Respect for cultural heritage:**  Protect cultural heritage from potential harm caused by AI systems, such as the spread of misinformation or the appropriation of cultural artifacts.\n",
      "    *   **Recognize diverse perspectives:**  Acknowledge that ethical considerations may vary across cultures and avoid imposing a single, universal ethical framework.\n",
      "    *   **Promote cross-cultural dialogue:**  Facilitate dialogue and collaboration between different cultures to foster a shared understanding of ethical AI.\n",
      "\n",
      "**IV. Implementation and Enforcement:**\n",
      "\n",
      "*   **Self-regulation:** Encourage industry self-regulation through the development of ethical codes of conduct and best practices.\n",
      "*   **Certification and auditing:**  Establish certification and auditing programs to ensure that AI systems meet ethical standards.\n",
      "*   **Regulatory oversight:**  Implement regulatory oversight and enforcement mechanisms to address egregious violations of ethical principles.\n",
      "*   **Liability frameworks:**  Clarify liability frameworks for harms caused by AI systems.\n",
      "*   **Education and awareness:**  Promote education and awareness of ethical issues in AI among the general public.\n",
      "\n",
      "**V. Ongoing Review and Adaptation:**\n",
      "\n",
      "*   **Regular evaluation:**  Regularly evaluate the effectiveness of the ethical framework and make adjustments as needed to reflect technological advancements and evolving societal values.\n",
      "*   **Continuous learning:**  Stay abreast of the latest research and best practices in ethical AI.\n",
      "*   **Adaptable framework:**  Design the framework to be flexible and adaptable to new challenges and opportunities presented by AI.\n",
      "\n",
      "**Key Considerations for Success:**\n",
      "\n",
      "*   **Strong leadership:**  Effective leadership is crucial to drive the development and implementation of the ethical framework.\n",
      "*   **Collaboration and coordination:**  Collaboration and coordination among stakeholders are essential for building consensus and ensuring that the framework is effectively implemented.\n",
      "*   **Resources:**  Adequate resources are needed to support research, development, and implementation of ethical AI practices.\n",
      "*   **Political will:**  Political will is needed to enact and enforce regulations and policies that promote ethical AI.\n",
      "*   **Public trust:** Building and maintaining public trust in AI is essential for its widespread adoption and acceptance.\n",
      "\n",
      "By following this comprehensive approach, we can create an ethical framework for AI systems that balances innovation and safety, while considering diverse cultural perspectives and potential socio-economic impacts, ultimately ensuring that AI serves humanity in a responsible and beneficial way. It's a continuous journey, requiring vigilance, adaptation, and a commitment to ethical principles.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Designing an ethical framework for AI systems requires a multidisciplinary approach that considers various factors, including technical, social, and economic aspects. Here's a comprehensive framework to balance innovation with safety, diversity, and socio-economic considerations:\n",
      "\n",
      "1. **Establish a Clear Purpose and Scope**:\n",
      " Define the purpose of the AI system, its intended use cases, and the stakeholders involved. This will help identify potential risks and benefits, as well as the necessary safeguards.\n",
      "2. **Conduct Thorough Risk Assessments**:\n",
      " Perform comprehensive risk assessments to understand potential threats and opportunities. Identify potential risks, such as data bias, bias in decision-making, or unintended consequences on society.\n",
      "3. **Develop a Human-Centered Approach**:\n",
      " Prioritize human needs, dignity, and well-being in AI system design. Ensure that the framework takes into account diverse cultural perspectives, values, and contexts to prevent cultural homogenization or exploitation.\n",
      "4. **Foster Collaboration and Stakeholder Engagement**:\n",
      " Engage with diverse stakeholders, including experts from various fields (e.g., ethics, law, sociology), industry representatives, policymakers, and community representatives to ensure that the AI system is aligned with societal values and needs.\n",
      "5. **Incorporate Transparency and Explainability**:\n",
      " Develop techniques to explain AI decision-making processes and provide transparent outputs. This will enable users to understand how AI systems make decisions and promote accountability.\n",
      "6. **Emphasize Fairness, Accountability, and Resilience**:\n",
      " Incorporate principles of fairness, accountability, and resilience into the framework. Ensure that AI systems are fair, unbiased, and resilient in the face of failures or cyber-attacks.\n",
      "7. **Consider Socio-Economic Impacts**:\n",
      " Assess potential socio-economic impacts, including job displacement, inequality, or amplification of existing biases. Develop mitigation strategies to minimize these effects.\n",
      "8. **Establish Robust Auditing and Monitoring Processes**:\n",
      " Regularly audit and monitor AI systems for compliance with the framework's principles and ensure that necessary safeguards are in place.\n",
      "9. **Continuously Evaluate and Update the Framework**:\n",
      " Regularly review and update the framework to address emerging challenges, technical advancements, or new societal values.\n",
      "10. **Promote Public Engagement and Education**:\n",
      " Educate stakeholders and the public about AI-related issues and promote informed discussions on AI development and deployment.\n",
      "\n",
      "Some additional considerations:\n",
      "\n",
      "*   **Accountability Mechanisms**: Establish accountability mechanisms for AI system developers, users, and regulators to ensure that the framework is enforced and respected.\n",
      "*   **Global Harmonization**: Foster international cooperation to develop harmonized standards for AI ethics and governance, ensuring consistency across borders.\n",
      "*   **Research and Development**: Support ongoing research and development to improve understanding of AI systems' potential risks and benefits.\n",
      "\n",
      "By incorporating these elements into an ethical framework for AI systems, we can ensure that innovation is balanced with safety, diversity, and socio-economic considerations.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:41.203014Z",
     "start_time": "2025-08-21T09:02:41.201545Z"
    }
   },
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:48.536017Z",
     "start_time": "2025-08-21T09:02:41.209849Z"
    }
   },
   "source": [
    "# Judgement time!\n",
    "\n",
    "response = dial.chat.completions.create(\n",
    "    model=\"o3-mini-2025-01-31\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"3\", \"1\", \"2\", \"4\"]}\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T09:02:48.556311Z",
     "start_time": "2025-08-21T09:02:48.553756Z"
    }
   },
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini-2024-07-18\n",
      "Rank 3: claude-3-7-sonnet@20250219\n",
      "Rank 4: llama3.2\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
